# ğŸ“° News Trend Analysis

**Automated news aggregation and analysis system with sentiment analysis, topic modeling, and interactive visualization dashboard.**

[![Live Demo](https://img.shields.io/badge/Live%20Demo-Railway-blue)](https://newstrendanalysis.up.railway.app/)
[![Python](https://img.shields.io/badge/Python-3.11+-green.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> ğŸ“ **University Projects**: 
> - **MOPJ (NLP)**: Automated NLP pipeline with sentiment analysis, topic modeling, and summarization
> - **PI (Business Intelligence)**: Predictive analytics dashboard with comprehensive evaluation system

## ğŸ¯ Business Problem

**Challenge**: Manual tracking of economic news sentiment is time-consuming and subjective.

**Solution**: Automated AI-powered pipeline that:
- Fetches economic news every 12 hours
- Analyzes sentiment with 76% confidence (FinBERT)
- Discovers trending topics automatically (BERTopic)
- Generates concise summaries (37.7x compression)
- Visualizes insights in interactive dashboard

**Business Value**:
- ğŸ“ˆ **Investors**: Real-time market sentiment tracking
- ğŸ“° **Media**: Identify trending topics and narratives
- ğŸ“Š **Analysts**: Automated research assistance

## ğŸŒŸ Features

- ğŸ¤– **Automated News Collection**: Fetches latest economic news from NewsData.io API
- ğŸ•·ï¸ **Web Scraping**: Extracts full article content from news websites
- ğŸ§  **Advanced NLP Analysis**:
  - **Sentiment Analysis**: FinBERT transformer model (Prosus AI)
  - **Topic Modeling**: BERTopic with HDBSCAN clustering
  - **Automatic Summarization**: DistilBART (CNN-trained)
- ğŸ“Š **Interactive Dashboard**: Real-time visualization with Streamlit + Plotly
- âš¡ **Automated Pipeline**: GitHub Actions runs twice daily (8:00 & 20:00 UTC)
- ğŸ¯ **Quality Filtering**: Removes paid content and short articles (< 200 words)
- ğŸ”„ **Duplicate Detection**: Smart handling of cross-source articles
- ğŸ”® **Predictive Analytics** (NEW):
  - **Weekly Forecasting**: Elastic Net + XGBoost for sentiment/volume predictions
  - **Spike Detection**: ML-based anomaly detection with SMOTE balancing
  - **Feature Engineering**: Lag, rolling, calendar, and trend features
  - **REST API**: FastAPI endpoints for predictions

## ğŸš€ Live Demo

**Dashboard**: [https://newstrendanalysis.up.railway.app/](https://newstrendanalysis.up.railway.app/)

## ğŸ“¸ Screenshots

### Dashboard Overview
- **4 Key Metrics**: Total articles, unique articles, sentiment, topics
- **Interactive Charts**: Sentiment distribution, topic clustering, time series
- **Smart Pagination**: Browse articles with customizable page size
- **Advanced Filtering**: By sentiment, topic, and date

### Features
- âœ… **Sentiment Over Time**: Track market sentiment trends
- âœ… **Topic Distribution**: Visualize news themes
- âœ… **Article Summaries**: AI-generated summaries for quick insights
- âœ… **Duplicate Toggle**: Show/hide articles from multiple sources

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|----------|-------------|
| **Language** | Python 3.11+ |
| **NLP Models** | Transformers (FinBERT, DistilBART), BERTopic, Sentence-Transformers |
| **Predictive ML** | XGBoost, Elastic Net, SMOTE (imbalanced-learn), Optuna |
| **Dashboard** | Streamlit, Plotly |
| **API** | FastAPI, Pydantic |
| **Deployment** | Railway (dashboard), GitHub Actions (pipeline) |
| **Data Source** | NewsData.io API |
| **Web Scraping** | Newspaper3k, BeautifulSoup |

## ğŸ“¦ Installation

### Prerequisites
- Python 3.11 or higher
- NewsData.io API key ([Get free key](https://newsdata.io/))

### Quick Start

1. **Clone Repository**
```bash
git clone https://github.com/davidjosipovic/news-trend-analysis.git
cd news-trend-analysis
```

2. **Create Virtual Environment**
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or
.venv\Scripts\activate  # Windows
```

3. **Install Dependencies**

For full pipeline (includes NLP models ~2GB):
```bash
pip install -r requirements.full.txt
```

For dashboard only (lightweight ~50MB):
```bash
pip install -r requirements.txt
```

4. **Configure API Key**
```bash
echo "NEWS_API_KEY=your_api_key_here" > .env
```

## ğŸ¯ Usage

### Option 1: Run Full Pipeline

Execute complete analysis pipeline:

```bash
# Step 1: Fetch news articles
python src/fetch_articles.py

# Step 2: Scrape full content
python src/scrape_articles.py

# Step 3: Clean and preprocess
python src/preprocess_articles.py

# Step 4: Sentiment analysis
python src/analyze_sentiment.py

# Step 5: Topic modeling
python src/discover_topics.py

# Step 6: Generate summaries
python src/summarize_articles.py

# Step 7: Evaluate pipeline quality
python src/evaluate_pipeline.py
```

### Option 2: Run Dashboard Only

```bash
streamlit run dashboard/streamlit_app.py
```

Access dashboard at: `http://localhost:8501`

## ğŸ“ Project Structure

```
news-trend-analysis/
â”œâ”€â”€ ğŸ“‚ src/                          # Core processing pipeline
â”‚   â”œâ”€â”€ fetch_articles.py            # NewsData.io API integration
â”‚   â”œâ”€â”€ scrape_articles.py           # Web scraper (newspaper3k)
â”‚   â”œâ”€â”€ preprocess_articles.py       # Text cleaning & filtering
â”‚   â”œâ”€â”€ analyze_sentiment.py         # FinBERT sentiment inference
â”‚   â”œâ”€â”€ discover_topics.py           # BERTopic clustering
â”‚   â”œâ”€â”€ summarize_articles.py        # DistilBART summarization
â”‚   â””â”€â”€ evaluate_pipeline.py         # Quality metrics & reporting
â”‚
â”œâ”€â”€ ğŸ“‚ dashboard/
â”‚   â”œâ”€â”€ streamlit_app.py             # Interactive Streamlit dashboard
â”‚   â””â”€â”€ predictive_components.py     # Predictive analytics UI components
â”‚
â”œâ”€â”€ ğŸ“‚ features/                     # Feature engineering module
â”‚   â””â”€â”€ time_features.py             # Time series feature generation
â”‚
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”œâ”€â”€ topic_model/                 # Saved BERTopic models
â”‚   â””â”€â”€ predictive/                  # Predictive ML models
â”‚       â”œâ”€â”€ weekly_forecaster.py     # Elastic Net + XGBoost forecaster
â”‚       â”œâ”€â”€ spike_detector.py        # Anomaly/spike detection
â”‚       â””â”€â”€ model_trainer.py         # Unified training pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ api/
â”‚   â””â”€â”€ prediction_api.py            # FastAPI REST endpoints
â”‚
â”œâ”€â”€ ğŸ“‚ config/
â”‚   â””â”€â”€ config.yaml                  # Centralized configuration
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                        # Test suite
â”‚   â”œâ”€â”€ test_features.py             # Feature engineering tests
â”‚   â”œâ”€â”€ test_models.py               # Model tests
â”‚   â””â”€â”€ test_api.py                  # API integration tests
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                         # Raw JSON from API
â”‚   â”‚   â”œâ”€â”€ news_*.json              # Fetched articles
â”‚   â”‚   â””â”€â”€ articles_scraped.json    # Scraped content
â”‚   â””â”€â”€ processed/                   # Processed CSV datasets
â”‚       â”œâ”€â”€ articles.csv
â”‚       â”œâ”€â”€ articles_with_sentiment.csv
â”‚       â”œâ”€â”€ articles_with_topics.csv
â”‚       â””â”€â”€ articles_with_summary.csv
â”‚
â”œâ”€â”€ ğŸ“‚ .github/workflows/
â”‚   â””â”€â”€ daily-update.yml             # Automated pipeline (2x daily)
â”‚
â”œâ”€â”€ run_pipeline.py                  # Complete pipeline runner
â”œâ”€â”€ requirements.txt                 # Lightweight deps (dashboard)
â”œâ”€â”€ requirements.full.txt            # Full deps (NLP pipeline)
â””â”€â”€ README.md
```

## ğŸ¨ Dashboard Features

### ğŸ“Š Metrics & Visualizations

| Feature | Description |
|---------|-------------|
| **Total Articles** | Count of all processed articles |
| **Unique Articles** | Articles after duplicate removal |
| **Sentiment Distribution** | Pie chart of positive/neutral/negative |
| **Topics by Article** | Bar chart of topic distribution |
| **Sentiment Over Time** | Line chart tracking sentiment trends |

### ğŸ›ï¸ Interactive Controls

- **Sentiment Filter**: Show only positive/neutral/negative articles
- **Topic Filter**: Filter by specific topic cluster
- **Sort Order**: Newest first / Oldest first
- **Pagination**: 5-50 articles per page
- **Duplicate Toggle**: Show/hide cross-source duplicates

## âš™ï¸ Configuration

### Data Quality Filters

Articles are **automatically filtered** based on:

| Filter | Threshold | Reason |
|--------|-----------|--------|
| **Minimum Words** | 200+ words | Ensures substantive content for analysis |
| **Paid Content** | Excluded | Removes "ONLY AVAILABLE IN PAID PLANS" |
| **Duplicate Titles** | Optional | Toggle to show/hide cross-source articles |

### Models

| Task | Model | Source | Why This Model? |
|------|-------|--------|-----------------|
| **Sentiment** | `ProsusAI/finbert` | HuggingFace | Fine-tuned on **financial news** (better for economic articles than Twitter-based models) |
| **Embeddings** | `all-MiniLM-L6-v2` | Sentence-Transformers | Fast, efficient semantic embeddings |
| **Summarization** | `sshleifer/distilbart-cnn-12-6` | HuggingFace | Compressed BART trained on **CNN news articles** |
| **Topic Modeling** | BERTopic + HDBSCAN | Custom configuration | Unsupervised clustering with auto-generated labels |

## ğŸš¢ Deployment

### Railway (Dashboard)
```bash
# Automatic deployment on git push
# Uses: requirements.txt (lightweight)
# Environment variables: NEWS_API_KEY
```

### GitHub Actions (Pipeline)
```yaml
# Runs twice daily: 8:00 AM & 8:00 PM UTC
# Uses: requirements.full.txt (full NLP)
# Commits processed data back to repo
```

## ğŸ“Š Data Flow

```
NewsData.io API â†’ fetch_articles.py â†’ scrape_articles.py â†’ preprocess_articles.py 
                                                                      â†“
                        evaluate_pipeline.py â† summarize_articles.py â† discover_topics.py â† analyze_sentiment.py
                                  â†“
                            Dashboard (Streamlit)
```

## ğŸ”¬ Analysis Details

### Why Pre-trained Models? (No Training Required)

This project uses **transfer learning** - applying pre-trained models rather than training from scratch. This approach is:

1. **Industry Standard**: Pre-trained transformers (FinBERT, BART) are trained on billions of tokens
2. **More Accurate**: FinBERT trained on 4.9M financial sentences vs. our 55 articles
3. **Practical**: Training BERT from scratch requires 4 TPUs for 4 days (~$500-1000)
4. **Academic**: Demonstrates proper use of state-of-the-art NLP (BERT, transformers)

**Models Used:**
- **FinBERT**: Fine-tuned BERT for financial sentiment (Prosus AI)
- **DistilBART**: Distilled BART for news summarization (trained on CNN/DailyMail)
- **BERTopic**: Unsupervised topic discovery (no training needed)

### Sentiment Analysis
- **Model**: Fine-tuned RoBERTa with custom adapter (default)
  - Base: `cardiffnlp/twitter-roberta-base-sentiment-latest`
  - **Adapter**: Custom fine-tuned on domain-specific data
- **Output**: Positive, Neutral, Negative (with confidence scores)
- **Inference**: Batch processing on CPU
- **Advantages**: 
  - Domain-specific fine-tuning for better accuracy
  - 69% non-neutral classification (vs 35% for base model)
  - Better detection of subtle sentiment in news articles

**Using the Adapter:**
```bash
# Default: Uses adapter automatically if available
python src/analyze_sentiment.py

# Force base model
python src/analyze_sentiment.py --no-adapter

# Compare models
python compare_models.py --adapter-path ./models/sentiment_adapter_best
```

For more details, see [README_ADAPTER.md](README_ADAPTER.md)

### Topic Modeling
- **Algorithm**: HDBSCAN clustering on sentence embeddings
- **Dimensionality Reduction**: UMAP
- **Labels**: Auto-generated using KeyBERT (unsupervised)
- **Dynamic**: Discovers new topics as articles grow (no predefined categories)

### Summarization
- **Model**: DistilBART (compressed BART for efficiency)
- **Length**: 30-130 tokens per summary
- **Quality**: Requires 200+ word articles
- **Batch Processing**: Handles 8 articles simultaneously

## ğŸ“Š Results & Evaluation

### Overall Pipeline Quality: **85/100** (GOOD)

#### Sentiment Analysis Results:
```
ğŸ“‰ Negative:  10 articles (18.2%)
âšª Neutral:   28 articles (50.9%)
ğŸ“ˆ Positive:  17 articles (30.9%)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Average Confidence: 76.0%
```

**Key Improvement**: Switched from Twitter-RoBERTa (68% confidence, 1.8% negative detection) to FinBERT (76% confidence, 18.2% negative detection) for better financial news understanding.

#### Topic Discovery Results:
```
Discovered 6 coherent topics:
1. Korea_Trump_China           - 16 articles (29%)
2. Economic_Sector_Sustainable - 9 articles (16%)
3. Inflation_Forecasts         - 8 articles (15%)
4. Tourism_Travel              - 7 articles (13%)
5. Reforms_Economy             - 6 articles (11%)
6. Business_Development        - 4 articles (7%)

Topic Quality Score: 100/100
```

#### Summarization Performance:
```
âœ“ Coverage: 100% (all articles summarized)
âœ“ Avg length: 51 words
âœ“ Compression ratio: 37.7x (from ~800 â†’ 51 words)
âœ“ Processing time: ~5s per article (CPU)
```

### Evaluation Metrics (6 categories):
1. **Data Quality** (30% weight): 100/100
   - 100% completeness, proper filtering
2. **Sentiment Balance** (15% weight): 0/100
   - Expected imbalance (economic news naturally more negative/neutral)
3. **Topic Quality** (25% weight): 100/100
   - Coherent clusters, balanced distribution
4. **Summarization** (30% weight): 100/100
   - Full coverage, appropriate compression
5. **Temporal Analysis**: 2-day coverage with automated updates
6. **Confidence Tracking**: Real-time monitoring of prediction reliability

### Business Insights:
- **US-China relations** dominate economic news (29%)
- **Sustainability** emerging as major economic theme
- **Inflation concerns** persist across multiple articles
- **Tourism sector** showing recovery signals

## ğŸ”® Predictive Analytics

### Overview

The predictive analytics module provides ML-based forecasting capabilities:

| Feature | Description |
|---------|-------------|
| **Weekly Forecaster** | Predicts avg sentiment and article volume 7 days ahead |
| **Spike Detector** | Identifies anomalous news activity with probability scores |
| **Feature Engineering** | Automated time series feature generation |
| **REST API** | FastAPI endpoints for programmatic access |

### Models

#### 1. Weekly Forecaster (Dual-Model Approach)
- **Elastic Net** (interpretable baseline): Linear model with L1+L2 regularization
- **XGBoost** (high accuracy): Gradient boosting for complex patterns
- **Targets**: `avg_sentiment` and `total_articles`
- **Horizon**: 7 days

#### 2. Spike Detector
- **Algorithm**: XGBoost Classifier
- **SMOTE Balancing**: Handles class imbalance (spikes are rare)
- **Definition**: volume > mean + 2Ïƒ OR sentiment_change > 0.5
- **Output**: Probability (0-1) + Risk level (MINIMAL/LOW/MEDIUM/HIGH)

### Feature Engineering

Automatically generates 50+ features from daily aggregates:

| Category | Features |
|----------|----------|
| **Lag Features** | 1, 2, 3, 7, 14 day lags for sentiment/volume |
| **Rolling Features** | Mean, std, min, max over 3, 7, 14, 30 day windows |
| **Calendar Features** | Day of week, weekend, month, Croatian holidays |
| **Trend Features** | Momentum, acceleration, trend direction |

### API Endpoints

```bash
# Weekly predictions
GET /api/predictions/weekly

# Spike probability
GET /api/predictions/spike-probability

# Trend analysis
GET /api/analytics/trends?period=30

# Daily aggregates
GET /api/data/daily-aggregates?days=7

# Retrain models (protected)
POST /api/models/retrain
```

**Start API Server:**
```bash
uvicorn api.prediction_api:app --reload --port 8000
```

### Training Pipeline

```python
from models.predictive.model_trainer import ModelTrainer
from features.time_features import TimeSeriesFeatureEngineer
import pandas as pd

# Load data
df = pd.read_csv('data/processed/articles_with_sentiment.csv')

# Generate features
engineer = TimeSeriesFeatureEngineer()
features_df = engineer.create_all_features(df)

# Train all models
trainer = ModelTrainer(n_splits=5, use_optuna=True)
results = trainer.train_all_models(features_df)

# Save models
trainer.save_models('models/predictive/')
```

### Time Series Validation

Uses **walk-forward validation** (TimeSeriesSplit) instead of random split:

```
Training: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] â†’ Test: [â–‘â–‘â–‘â–‘]
Training: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] â†’ Test: [â–‘â–‘â–‘â–‘]
Training: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] â†’ Test: [â–‘â–‘â–‘â–‘]
```

This prevents data leakage from future observations.

### Dashboard Integration

The Streamlit dashboard includes a **Predictive Analytics** tab with:
- ğŸ“Š Predicted vs Actual charts
- ğŸ”” Spike probability gauge
- ğŸ“ˆ Feature importance visualization
- âš ï¸ Real-time spike alerts

### Configuration

All hyperparameters in `config/config.yaml`:

```yaml
models:
  weekly_forecaster:
    forecast_horizon: 7
    elastic_net:
      alpha: 1.0
      l1_ratio: 0.5
    xgboost:
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
  
  spike_detector:
    volume_std_threshold: 2.0
    sentiment_change_threshold: 0.5
    use_smote: true
```

## ğŸ§ª Testing

Run the test suite:

```bash
# All tests
pytest tests/ -v

# Feature engineering tests
pytest tests/test_features.py -v

# Model tests
pytest tests/test_models.py -v

# API integration tests
pytest tests/test_api.py -v
```

## ğŸ¤ Contributing

This is a university project, but suggestions are welcome!

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -m 'Add feature'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open Pull Request

## ğŸ“ License

MIT License - feel free to use for educational purposes

## ğŸ‘¨â€ğŸ’» Author

**Built as a university project** demonstrating:
- Automated NLP pipeline design
- Real-time data visualization
- Cloud deployment (Railway + GitHub Actions)
- Modern Python best practices

## ğŸ™ Acknowledgments

- **NewsData.io** for free news API access
- **HuggingFace** for pre-trained transformer models
- **Streamlit** for rapid dashboard development
---

â­ **Star this repo** if you found it helpful for your own projects!
